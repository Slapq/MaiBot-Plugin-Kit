# é«˜çº§åŠŸèƒ½æŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ `mai_advanced` æ‰©å±•å±‚å®ç°è¶…è¶ŠåŸºç¡€æ¨¡æ¿çš„é«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

- **è‡ªå®šä¹‰æç¤ºè¯å›å¤** â€” å®Œå…¨æ§åˆ¶ LLM çš„è¾“å…¥
- **å›å¤ç»„ä»¶æ³¨å…¥** â€” åœ¨æ­£å¸¸å›å¤çš„å‰/åæ’å…¥å†…å®¹
- **å›å¤é‡å†™** â€” ç”¨éº¦éº¦çš„è¯­æ°”è¯´å‡ºä½ çš„å†…å®¹
- **ç›´æ¥è°ƒç”¨åº•å±‚ LLM** â€” ä¸ç»è¿‡äººæ ¼/ä¸Šä¸‹æ–‡å±‚

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£… Advanced æ¨¡æ¿

```bash
python -m mai_plugin_cli create my_plugin --template advanced
```

è¿™ä¼šç”ŸæˆåŒ…å«æ‰€æœ‰é«˜çº§åŠŸèƒ½ç¤ºä¾‹çš„å®Œæ•´æ’ä»¶ã€‚

---

## `mai_advanced` æ¨¡å—è¯´æ˜

### å¯¼å…¥æ–¹å¼

```python
from mai_advanced import AdvancedReplyBuilder, ReplyComponent, PromptModifier
```

> âš ï¸ `mai_advanced` éœ€è¦æ”¾åœ¨ MaiBot çš„ `plugins/` åŒçº§ç›®å½•ï¼ˆæˆ–å®‰è£…ä¸ºåŒ…ï¼‰ã€‚  
> æ›´ç®€å•çš„æ–¹å¼ï¼šæŠŠ `mai_advanced/` ç›®å½•å¤åˆ¶åˆ°ä½ çš„æ’ä»¶ç›®å½•æ—ã€‚

---

## åŠŸèƒ½ä¸€ï¼šè‡ªå®šä¹‰æç¤ºè¯å›å¤

é€‚ç”¨äºï¼šä¸´æ—¶è§’è‰²æ‰®æ¼”ã€ä¸“ä¸šé—®ç­”ã€å®Œå…¨ä¸æƒ³ç”¨éº¦éº¦äººæ ¼çš„åœºæ™¯ã€‚

```python
from mai_advanced import AdvancedReplyBuilder

class MyAction(BaseAction):
    async def execute(self):
        builder = AdvancedReplyBuilder(self)

        # æ„é€ å®Œå…¨è‡ªå®šä¹‰çš„æç¤ºè¯
        ok, result = await builder.generate_custom_reply(
            prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­åŒ»å¸ˆã€‚
ç”¨æˆ·é—®ï¼šå¤´ç–¼æ€ä¹ˆåŠï¼Ÿ
è¯·ç»™å‡º 3 æ¡å®ç”¨å»ºè®®ã€‚""",
            send_result=True,  # è‡ªåŠ¨å‘é€
        )

        return ok, "å®Œæˆ"
```

**åº•å±‚ APIï¼š** `generator_api.generate_response_custom(chat_stream, prompt)`

---

## åŠŸèƒ½äºŒï¼šæç¤ºè¯æ³¨å…¥ï¼ˆåœ¨åŸæœ‰æç¤ºè¯ä¸­è¿½åŠ ä¿¡æ¯ï¼‰

é€‚ç”¨äºï¼šæƒ³ä¿ç•™éº¦éº¦çš„äººæ ¼å’Œä¸Šä¸‹æ–‡ï¼Œä½†éœ€è¦è¿½åŠ é¢å¤–çŸ¥è¯†æˆ–æŒ‡ä»¤ã€‚

```python
builder = AdvancedReplyBuilder(self)

# extra_info ä¼šè¿½åŠ åˆ°éº¦éº¦é»˜è®¤æç¤ºè¯çš„æœ«å°¾
await builder.generate_reply(
    extra_info="ä»¥ä¸‹æ˜¯ä»Šæ—¥æ–°é—»æ‘˜è¦ï¼š[æ–°é—»å†…å®¹...]\n\nè¯·åŸºäºä»¥ä¸Šå†…å®¹å›ç­”"
)
```

**åº•å±‚ APIï¼š** `generator_api.generate_reply(..., extra_info="...", return_prompt=True)`

---

## åŠŸèƒ½ä¸‰ï¼šå›å¤ç»„ä»¶æ³¨å…¥ï¼ˆå‰ç½®/åç½®ï¼‰

é€‚ç”¨äºï¼šåœ¨éº¦éº¦æ­£å¸¸å›å¤çš„å‰/åè¿½åŠ è‡ªå®šä¹‰å†…å®¹ã€‚

```python
from mai_advanced import AdvancedReplyBuilder, ReplyComponent

builder = AdvancedReplyBuilder(self)

await builder.generate_reply(
    extra_info="è¯·ç”¨çƒ­æƒ…çš„è¯­æ°”å›å¤",

    # åœ¨æ­£å¸¸å›å¤ã€ä¹‹å‰ã€‘å‘é€
    prepend=[
        ReplyComponent.text("ğŸ¤” æ­£åœ¨æ€è€ƒ...", typing=True),
    ],

    # åœ¨æ­£å¸¸å›å¤ã€ä¹‹åã€‘å‘é€
    append=[
        ReplyComponent.text("ğŸ’¡ å¦‚æœ‰ç–‘é—®è¯·ç»§ç»­é—®æˆ‘ï¼"),
    ],
)
```

### ReplyComponent ç±»å‹

| ç±»å‹ | åˆ›å»ºæ–¹å¼ | è¯´æ˜ |
|------|----------|------|
| æ–‡æœ¬ | `ReplyComponent.text("å†…å®¹")` | æ™®é€šæ–‡æœ¬ï¼Œæ”¯æŒ `typing=True` å’Œ `reply_to` |
| è¡¨æƒ…åŒ… | `ReplyComponent.emoji(base64)` | å‘é€è¡¨æƒ…åŒ… |
| å›¾ç‰‡ | `ReplyComponent.image(base64)` | å‘é€å›¾ç‰‡ |
| è‡ªå®šä¹‰ | `ReplyComponent("type", "content")` | ä»»æ„æ¶ˆæ¯ç±»å‹ |

---

## åŠŸèƒ½å››ï¼šå›å¤é‡å†™

é€‚ç”¨äºï¼šä½ æœ‰ç°æˆçš„æ–‡å­—ï¼ˆå¦‚ API è¿”å›çš„æ ¼å¼åŒ–å†…å®¹ï¼‰ï¼Œå¸Œæœ›éº¦éº¦ç”¨è‡ªå·±çš„è¯­æ°”è¯´å‡ºæ¥ã€‚

```python
builder = AdvancedReplyBuilder(self)

# è·å–å¤–éƒ¨æ•°æ®ï¼ˆå¦‚å¤©æ°” APIï¼‰
weather_data = "åŒ—äº¬ï¼šæ™´ï¼Œ25Â°Cï¼Œå¾®é£"

# ç”¨éº¦éº¦é£æ ¼é‡å†™ï¼ˆä¿ç•™åˆ†å¥ã€è¯­æ°”ç­‰ä¸ªæ€§åŒ–ç‰¹å¾ï¼‰
ok, components = await builder.rewrite_reply(
    raw_reply=weather_data,
    reason="å°†å¤©æ°”ä¿¡æ¯è½¬æˆéº¦éº¦çš„å£å»"
)

if ok:
    await builder.send_components(components)
```

**åº•å±‚ APIï¼š** `generator_api.rewrite_reply(chat_stream, raw_reply, reason, reply_to)`

---

## åŠŸèƒ½äº”ï¼šç›´æ¥è°ƒç”¨åº•å±‚ LLM

é€‚ç”¨äºï¼šéœ€è¦ç²¾ç¡®æ§åˆ¶æ¨¡å‹å‚æ•°ã€ä½¿ç”¨ç‰¹å®šæ¨¡å‹ã€è·å– JSON/ä»£ç ç­‰ç»“æ„åŒ–è¾“å‡ºã€‚

```python
from mai_advanced import PromptModifier

modifier = PromptModifier(self)

# åˆ—å‡ºå¯ç”¨æ¨¡å‹
models = modifier.get_available_models()
print(list(models.keys()))  # ['gpt-4o', 'deepseek-v3', ...]

# è°ƒç”¨æŒ‡å®šæ¨¡å‹
ok, result = await modifier.call_model(
    prompt="è¯·ç”¨ JSON æ ¼å¼è¿”å›åŒ—äº¬çš„å¤©æ°”ï¼š{\"city\": ..., \"temp\": ...}",
    model_name="deepseek-v3",   # æŒ‡å®šæ¨¡å‹ï¼ˆNone åˆ™ç”¨é»˜è®¤ï¼‰
    temperature=0.1,             # ä½æ¸©åº¦ = ç¡®å®šæ€§æ›´å¼º
    max_tokens=500,
)

if ok:
    import json
    data = json.loads(result)
```

**åº•å±‚ APIï¼š** `llm_api.generate_with_model(prompt, model_config, temperature, max_tokens)`

---

## åŠŸèƒ½å…­ï¼šå¸¦å·¥å…·è°ƒç”¨çš„ LLMï¼ˆFunction Callingï¼‰

```python
ok, content, tool_calls = await modifier.call_model_with_tools(
    prompt="è¯·æœç´¢ä»Šå¤©çš„å¤´æ¡æ–°é—»",
    tool_names=["web_search"],    # åªå¯ç”¨è¿™ä¸ªå·¥å…·
)

if tool_calls:
    for call in tool_calls:
        print(f"å·¥å…·: {call.name}ï¼Œå‚æ•°: {call.arguments}")
```

**åº•å±‚ APIï¼š** `llm_api.generate_with_model_with_tools(...)`

---

## åŠŸèƒ½ä¸ƒï¼šè·å–å®é™…æç¤ºè¯ï¼ˆè°ƒè¯•ï¼‰

```python
modifier = PromptModifier(self)
prompt = await modifier.get_actual_prompt(
    extra_info="[è°ƒè¯•æ¨¡å¼]"
)
print(prompt[:500])
```

**åº•å±‚ APIï¼š** `generator_api.generate_reply(..., return_prompt=True)`

---

## å®Œæ•´ API é€ŸæŸ¥è¡¨

### AdvancedReplyBuilder

| æ–¹æ³• | è¯´æ˜ | åº•å±‚ API |
|------|------|----------|
| `generate_reply(extra_info, prepend, append)` | å¸¦æ³¨å…¥çš„æ­£å¸¸å›å¤ç”Ÿæˆ | `generator_api.generate_reply` |
| `generate_custom_reply(prompt)` | å®Œå…¨è‡ªå®šä¹‰æç¤ºè¯å›å¤ | `generator_api.generate_response_custom` |
| `rewrite_reply(raw_reply, reason)` | ç”¨éº¦éº¦é£æ ¼é‡å†™å†…å®¹ | `generator_api.rewrite_reply` |
| `send_components(components)` | å‘é€ç»„ä»¶åˆ—è¡¨ | `send_api.text/emoji/image_to_stream` |
| `inject_before(*components)` | åœ¨å½“å‰ä½ç½®å‰ç½®æ³¨å…¥ | `send_api` |
| `inject_after(*components)` | åœ¨å½“å‰ä½ç½®åç½®æ³¨å…¥ | `send_api` |
| `get_prompt_preview(extra_info)` | è·å–å½“å‰ä¼šç”¨çš„æç¤ºè¯ | `generator_api.generate_reply(return_prompt=True)` |

### PromptModifier

| æ–¹æ³• | è¯´æ˜ | åº•å±‚ API |
|------|------|----------|
| `get_available_models()` | åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹ | `llm_api.get_available_models` |
| `call_model(prompt, model_name, temperature)` | ç›´æ¥è°ƒç”¨æ¨¡å‹ | `llm_api.generate_with_model` |
| `call_model_with_tools(prompt, tool_names)` | å¸¦å·¥å…·è°ƒç”¨çš„ LLM | `llm_api.generate_with_model_with_tools` |
| `generate_with_extra_context(extra_info)` | æ³¨å…¥ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆ | `generator_api.generate_reply` |
| `get_actual_prompt(extra_info)` | è·å–å®é™…æç¤ºè¯ | `generator_api.generate_reply(return_prompt=True)` |

---

## æ³¨æ„äº‹é¡¹

1. **ä¸èƒ½ç›´æ¥ä¿®æ”¹éº¦éº¦çš„"ä¸»åŠ¨å›å¤"** â€” éº¦éº¦åœ¨æ²¡æœ‰ Action/Command è§¦å‘çš„æƒ…å†µä¸‹è‡ªåŠ¨äº§ç”Ÿçš„å›å¤ï¼Œæ’ä»¶ç›®å‰æ— æ³•ç›´æ¥æ‹¦æˆªå’Œä¿®æ”¹ï¼Œåªèƒ½é€šè¿‡ Action åœ¨è§¦å‘æ—¶æ§åˆ¶ã€‚

2. **`extra_info` å’Œ `generate_response_custom` çš„åŒºåˆ«ï¼š**
   - `extra_info`ï¼šåœ¨ç°æœ‰æç¤ºè¯æœ«å°¾**è¿½åŠ **å†…å®¹ï¼Œéº¦éº¦çš„äººæ ¼ã€ä¸Šä¸‹æ–‡éƒ½ä¿ç•™
   - `generate_response_custom`ï¼šä½¿ç”¨**å…¨æ–°æç¤ºè¯**ï¼Œä¸é™„å¸¦ä»»ä½•ä¸Šä¸‹æ–‡

3. **`rewrite_reply` çš„é£æ ¼åŒ–å¤„ç†**ï¼šä¼šç»è¿‡éº¦éº¦çš„åˆ†å¥å™¨å’Œé”™åˆ«å­—æ¨¡å—ï¼Œé€‚åˆå¸Œæœ›ä¿ç•™éº¦éº¦è¯­æ°”çš„åœºæ™¯ã€‚

4. **å¼‚æ­¥è¦æ±‚**ï¼šæ‰€æœ‰æ–¹æ³•å‡ä¸º `async`ï¼Œå¿…é¡»åœ¨ `async def execute()` ä¸­ç”¨ `await` è°ƒç”¨ã€‚
